{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from binascii import hexlify \n",
    "from scapy.all import rdpcap\n",
    "import yaml\n",
    "import numpy as np\n",
    "from utils.dataframe_tools import generate_vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join('.', 'utils', 'f2v.yaml')\n",
    "with open(config_path, 'r') as f:\n",
    "    yaml_config = yaml.safe_load(f)['field_embedding_config']\n",
    "fields = list(yaml_config.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join('.', 'Data', 'Test', 'merge_tls_test_01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: .\\Data\\Test\\merge_tls_test_01.csv\n",
      "Processing field: 'eth.dst'\n",
      "  - Found 2 unique values. Vocab size (incl. OOV): 3\n",
      "Processing field: 'eth.dst.lg'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'eth.dst.ig'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'eth.src'\n",
      "  - Found 2 unique values. Vocab size (incl. OOV): 3\n",
      "Processing field: 'eth.src.lg'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'eth.src.ig'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'eth.type'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'ip.version'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'ip.hdr_len'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'ip.dsfield'\n",
      "  - Found 3 unique values. Vocab size (incl. OOV): 4\n",
      "Processing field: 'ip.dsfield.dscp'\n",
      "  - Found 3 unique values. Vocab size (incl. OOV): 4\n",
      "Processing field: 'ip.dsfield.ecn'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'ip.len'\n",
      "  - Found 206 unique values. Vocab size (incl. OOV): 207\n",
      "Processing field: 'ip.id'\n",
      "  - Found 1879 unique values. Vocab size (incl. OOV): 1880\n",
      "Processing field: 'ip.flags'\n",
      "  - Found 2 unique values. Vocab size (incl. OOV): 3\n",
      "Processing field: 'ip.flags.rb'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'ip.flags.df'\n",
      "  - Found 2 unique values. Vocab size (incl. OOV): 3\n",
      "Processing field: 'ip.flags.mf'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'ip.frag_offset'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'ip.ttl'\n",
      "  - Found 14 unique values. Vocab size (incl. OOV): 15\n",
      "Processing field: 'ip.proto'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'ip.checksum'\n",
      "  - Found 1246 unique values. Vocab size (incl. OOV): 1247\n",
      "Processing field: 'ip.src'\n",
      "  - Found 19 unique values. Vocab size (incl. OOV): 20\n",
      "Processing field: 'ip.dst'\n",
      "  - Found 27 unique values. Vocab size (incl. OOV): 28\n",
      "Processing field: 'tcp.srcport'\n",
      "  - Found 58 unique values. Vocab size (incl. OOV): 59\n",
      "Processing field: 'tcp.dstport'\n",
      "  - Found 33 unique values. Vocab size (incl. OOV): 34\n",
      "Processing field: 'tcp.stream'\n",
      "  - Found 57 unique values. Vocab size (incl. OOV): 58\n",
      "Processing field: 'tcp.len'\n",
      "  - Found 206 unique values. Vocab size (incl. OOV): 207\n",
      "Processing field: 'tcp.seq'\n",
      "  - Found 1396 unique values. Vocab size (incl. OOV): 1397\n",
      "Processing field: 'tcp.seq_raw'\n",
      "  - Found 1396 unique values. Vocab size (incl. OOV): 1397\n",
      "Processing field: 'tcp.ack'\n",
      "  - Found 567 unique values. Vocab size (incl. OOV): 568\n",
      "Processing field: 'tcp.ack_raw'\n",
      "  - Found 567 unique values. Vocab size (incl. OOV): 568\n",
      "Processing field: 'tcp.hdr_len'\n",
      "  - Found 4 unique values. Vocab size (incl. OOV): 5\n",
      "Processing field: 'tcp.flags'\n",
      "  - Found 7 unique values. Vocab size (incl. OOV): 8\n",
      "Processing field: 'tcp.flags.res'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'tcp.flags.ae'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'tcp.flags.cwr'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'tcp.flags.ece'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'tcp.flags.urg'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'tcp.flags.ack'\n",
      "  - Found 2 unique values. Vocab size (incl. OOV): 3\n",
      "Processing field: 'tcp.flags.push'\n",
      "  - Found 2 unique values. Vocab size (incl. OOV): 3\n",
      "Processing field: 'tcp.flags.reset'\n",
      "  - Found 2 unique values. Vocab size (incl. OOV): 3\n",
      "Processing field: 'tcp.flags.syn'\n",
      "  - Found 2 unique values. Vocab size (incl. OOV): 3\n",
      "Processing field: 'tcp.flags.fin'\n",
      "  - Found 2 unique values. Vocab size (incl. OOV): 3\n",
      "Processing field: 'tcp.window_size_value'\n",
      "  - Found 93 unique values. Vocab size (incl. OOV): 94\n",
      "Processing field: 'tcp.window_size'\n",
      "  - Found 93 unique values. Vocab size (incl. OOV): 94\n",
      "Processing field: 'tcp.checksum'\n",
      "  - Found 1427 unique values. Vocab size (incl. OOV): 1428\n",
      "Processing field: 'tcp.urgent_pointer'\n",
      "  - Found 1 unique values. Vocab size (incl. OOV): 2\n",
      "Processing field: 'reassembled_segments'\n",
      "  - Found 220 unique values. Vocab size (incl. OOV): 221\n",
      "\n",
      "Saving master vocabulary to: .\\Data\\Test\\merge_tls_test_01_vocab.yaml\n",
      "Vocabulary generation complete!\n"
     ]
    }
   ],
   "source": [
    "vocab_reflect = generate_vocabulary(csv_path, fields, os.path.join('.', 'Data', 'Test', 'merge_tls_test_01_vocab.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ether / IP / TCP 192.168.5.3:49767 > 40.99.10.66:https FA\n"
     ]
    }
   ],
   "source": [
    "path_tls_pcap = os.path.join('./', 'Data', 'Test', 'tls_test_01.pcapng') \n",
    "pcap_test = rdpcap(path_tls_pcap) \n",
    "packet_0 = pcap_test[0] \n",
    "print(packet_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_yaml(yaml_file):\n",
    "    with open(yaml_file, 'r') as f:\n",
    "        return yaml.safe_load(f)['protocols'] \n",
    "    \n",
    "def parse_packet(packet, protocols):\n",
    "    raw_data = bytes(packet)  # 获取数据包的原始字节\n",
    "    result = {}\n",
    "    current_offset = 0\n",
    "    current_proto = 'ETH'  # 从以太网层开始\n",
    "\n",
    "    while current_proto and current_offset < len(raw_data):\n",
    "        if current_proto not in protocols:\n",
    "            break\n",
    "\n",
    "        proto_def = protocols[current_proto]\n",
    "        result[current_proto] = {}\n",
    "        fields = proto_def['fields']\n",
    "\n",
    "        # 解析当前层字段\n",
    "        for field in fields:\n",
    "            offset = current_offset + field['offset']\n",
    "            length = field['length']\n",
    "            field_name = field['name']\n",
    "            field_type = field['type']\n",
    "\n",
    "            # 处理动态长度\n",
    "            if length == 'dynamic':\n",
    "                length = len(raw_data) - offset\n",
    "            else:\n",
    "                length = int(length)\n",
    "\n",
    "            # 提取字段数据\n",
    "            if offset + length <= len(raw_data):\n",
    "                field_data = raw_data[offset:offset + length]\n",
    "\n",
    "                # 根据类型转换\n",
    "                if field_type == 'hex':\n",
    "                    value = hexlify(field_data).decode('utf-8')\n",
    "                elif field_type == 'binary':\n",
    "                    value = bin(int.from_bytes(field_data, 'big'))[2:].zfill(length * 8) \n",
    "                    # [2:]: 删去二进制标志位0b, 只保留数据部分\n",
    "                    # zfill: 二进制直接去除会忽略左侧的0, 所以要填充\n",
    "                    if 'bitmask' in field: \n",
    "                        mask = field['bitmask'] # 十六进制直接是整数, 不用转换\n",
    "                        if isinstance(mask, str): \n",
    "                            mask = int(field['bitmask'], 16)\n",
    "                        value = bin(int(value, 2) & mask)[2:].zfill(length * 8)\n",
    "                        if 'shift' in field:\n",
    "                            value = bin(int(value, 2) >> field['shift'])[2:]\n",
    "                else:\n",
    "                    value = field_data\n",
    "\n",
    "                result[current_proto][field_name] = value\n",
    "\n",
    "        # 计算当前层长度并更新偏移量\n",
    "        layer_length = max(field['offset'] + (int(field['length']) if field['length'] != 'dynamic' else 0) \n",
    "                          for field in fields)\n",
    "        current_offset += layer_length\n",
    "\n",
    "        # 确定下一层协议\n",
    "        if 'next_layer_map' in proto_def:\n",
    "            proto_value = result[current_proto].get('Protocol')  # 示例：IP的Protocol字段\n",
    "            current_proto = proto_def['next_layer_map'].get(proto_value)\n",
    "        elif 'next_layer' in proto_def:\n",
    "            current_proto = proto_def['next_layer']\n",
    "        else:\n",
    "            current_proto = None\n",
    "\n",
    "    return result \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ETH': {'Destination_MAC': 'f42d06784ee9', 'Source_MAC': '6c2f804a964c', 'EtherType': '0800'}, 'IP': {'Version': '100', 'IHL': '45', 'Total_Length': '0034', 'Protocol': '06'}, 'TCP': {'Source_Port': '0000', 'Destination_Port': 'c0a8', 'Flags': '10111011'}, 'TLS': {'Content_Type': 'b2', 'Version': '915f', 'Length': 'c4a8'}}\n"
     ]
    }
   ],
   "source": [
    "protocol_rules =  load_from_yaml('./utils/fields.yaml') \n",
    "parsed_data = parse_packet(packet_0, protocol_rules) \n",
    "print(parsed_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fingerprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
