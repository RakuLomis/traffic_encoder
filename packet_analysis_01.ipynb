{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from utils.dataframe_tools import filter_out_nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/Test/merge_tls_test_01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_col = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frame_num']\n",
      "['eth', 'dst', 'ig']\n",
      "['eth', 'dst']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "test = 'frame_num' \n",
    "test1 = 'eth.dst.ig' \n",
    "test2 = 'eth.dst'\n",
    "a = test.split('.') \n",
    "b = test1.split('.') \n",
    "c = test2.split('.')\n",
    "print(a) \n",
    "print(b)\n",
    "print(c)\n",
    "print(c in b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protocol_tree_extract(list_fields: list, list_layers = ['eth', 'ip', 'tcp', 'tls']): \n",
    "    dict_fields = {} \n",
    "    for layer in list_layers: \n",
    "        for field in list_fields: \n",
    "\n",
    "    for field in list_fields: \n",
    "        s_field = field.split('.') \n",
    "        if len(s_field) == 1 and s_field[0] not in list_layers: # statistical information, like frame_num, reassembled_info \n",
    "            dict_fields['statistics'].append(s_field) \n",
    "            \n",
    "        if s_field[0] in list_layers: # layer prefix \n",
    "            if s_field[0] not in dict_fields.keys(): \n",
    "                last_len = len(s_field) \n",
    "                dict_fields[s_field[0]].append(s_field) \n",
    "            \n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nan_cols = df.columns[df.isna().all()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonan = df.drop(columns=all_nan_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_directory = './Data/Test/filter_nan' \n",
    "# path_tls_csv = os.path.join(path_test_directory, 'tls_test_01.pcapng.csv') \n",
    "# path_tls_reassemble_csv = os.path.join(path_test_directory, 'reassemble_tls_test_01.pcapng.csv') \n",
    "path_test_csv = os.path.join(path_test_directory, 'filter_nan_merge_tls_test_01.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1959, 190)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_test_csv, index_col='frame_num') \n",
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_df = df.notnull() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_true = {} \n",
    "for col_num in range(mask_df.shape[1]): \n",
    "    list_true_indices = list(mask_df[mask_df.iloc[:, col_num]].index) \n",
    "    dict_true[col_num] = list_true_indices  \n",
    "\n",
    "# for col in mask_df.columns: \n",
    "#     list_true_indices = list(mask_df[mask_df.loc[:, col]].index) \n",
    "#     dict_true[col] = list_true_indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous\n",
    "dict_block = {\n",
    "    'block': [], \n",
    "    'columns': [], \n",
    "    'rows': [] \n",
    "} \n",
    "\n",
    "block_flag = 0 \n",
    "last_key = 0\n",
    "last_value = dict_true[last_key] \n",
    "list_col = []\n",
    "for key, value in dict_true.items(): \n",
    "    if key == last_key: # init \n",
    "        dict_block['block'].append(block_flag) \n",
    "        list_col.append(key) \n",
    "        dict_block['columns'].append(list_col.copy()) \n",
    "        dict_block['rows'].append(dict_true[key]) \n",
    "    else: \n",
    "        if value == last_value: \n",
    "            dict_block['columns'][block_flag].append(key) \n",
    "        if value != last_value: \n",
    "            block_flag += 1 \n",
    "            dict_block['block'].append(block_flag) \n",
    "            list_col.clear() \n",
    "            list_col.append(key) \n",
    "            dict_block['columns'].append(list_col.copy()) \n",
    "            dict_block['rows'].append(dict_true[key]) \n",
    "            last_key = key \n",
    "            last_value =value \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_block = pd.DataFrame(dict_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:00, 826.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "block_values = dict_block['block'] \n",
    "columns_values = dict_block['columns'] \n",
    "rows_values = dict_block['rows'] \n",
    "\n",
    "list_sub_df = []\n",
    "\n",
    "for block_name, columns, rows in tqdm(zip(block_values, columns_values, rows_values)): \n",
    "    subset_rows = df.loc[rows]\n",
    "    sub_df = subset_rows.iloc[:, columns]\n",
    "    list_sub_df.append(sub_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_block = {\n",
    "    'block': [], \n",
    "    'columns': [], \n",
    "    'rows': [] \n",
    "} \n",
    "\n",
    "block_flag = 0 \n",
    "list_col = [] \n",
    "list_record_col = []\n",
    "for key, value in dict_true.items(): \n",
    "    if key not in list_record_col: \n",
    "        for ik, iv in dict_true.items(): \n",
    "            if iv == value: \n",
    "                if block_flag not in dict_block['block']: \n",
    "                    dict_block['block'].append(block_flag) \n",
    "                    dict_block['rows'].append(dict_true[key]) \n",
    "                list_col.append(ik) \n",
    "            if iv != value: \n",
    "                continue \n",
    "        dict_block['columns'].append(list_col.copy()) \n",
    "        list_record_col.extend(list_col.copy()) \n",
    "        list_col.clear()\n",
    "        block_flag += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_block = pd.DataFrame(dict_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_indices = list(mask_df[mask_df['tls_handshake_server_point_len']].index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "intesection_series = mask_df.all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
